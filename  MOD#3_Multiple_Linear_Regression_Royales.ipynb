{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f8ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Training Set): 54.144609187935615\n",
      "Mean Squared Error (Testing Set): 59.356214788266065\n"
     ]
    }
   ],
   "source": [
    "# Activity 2\n",
    "# Multiple Linear Regression\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('E:heart_cleveland_upload.csv')\n",
    "\n",
    "# Prepare the features and target variables\n",
    "X = data.drop('age', axis=1)\n",
    "y = data['age']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the multiple linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "train_predictions = model.predict(X_train)\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "train_mse = mean_squared_error(y_train, train_predictions)\n",
    "test_mse = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "print(\"Mean Squared Error (Training Set):\", train_mse)\n",
    "print(\"Mean Squared Error (Testing Set):\", test_mse)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0c292",
   "metadata": {},
   "outputs": [],
   "source": [
    " We calculate the mean squared error (MSE) \n",
    " by comparing the actual target values with the predicted values. \n",
    " The MSE measures the average squared difference \n",
    " between the predicted and actual values. \n",
    " The MSE for the training and \n",
    " testing sets is printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c020d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature        VIF\n",
      "0         sex   3.802781\n",
      "1          cp   7.321667\n",
      "2    trestbps  43.176799\n",
      "3        chol  23.895659\n",
      "4         fbs   1.260130\n",
      "5     restecg   2.186745\n",
      "6     thalach  36.474242\n",
      "7       exang   2.073729\n",
      "8     oldpeak   3.225743\n",
      "9       slope   3.117972\n",
      "10         ca   2.130740\n",
      "11       thal   2.791270\n",
      "12  condition   3.987740\n"
     ]
    }
   ],
   "source": [
    "# Multicolinearity\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('E:heart_cleveland_upload.csv')\n",
    "\n",
    "# Prepare the features and target variables\n",
    "X = data.drop('age', axis=1)\n",
    "\n",
    "# Calculate VIF for each independent variable\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Feature\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14cd747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "We then calculate the VIF for each independent variable \n",
    "using the variance_inflation_factor function \n",
    "from the statsmodels.stats.outliers_influence module.\n",
    "The VIF is calculated by providing the feature values (X.values)\n",
    "and the index of the current variable in the loop (i) \n",
    "to the variance_inflation_factor function.\n",
    "The results are stored in a DataFrame (vif), \n",
    "where each row represents an independent variable\n",
    "and its corresponding VIF.\n",
    "Finally, we print the DataFrame to display\n",
    "the VIF values for each independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d99b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature        P-value\n",
      "0       const  6.409317e-235\n",
      "1     thalach   1.670125e-12\n",
      "2    trestbps   2.259571e-07\n",
      "3          ca   1.373979e-06\n",
      "4        chol   3.686522e-03\n",
      "5       exang   5.588038e-02\n",
      "6         sex   1.013356e-01\n",
      "7         fbs   2.791351e-01\n",
      "8     restecg   3.466834e-01\n",
      "9          cp   4.388094e-01\n",
      "10  condition   6.297261e-01\n",
      "11      slope   8.174603e-01\n",
      "12       thal   8.314490e-01\n"
     ]
    }
   ],
   "source": [
    "# Model Selection\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('E:heart_cleveland_upload.csv')\n",
    "\n",
    "# Prepare the features and target variables\n",
    "X = data.drop('age', axis=1)\n",
    "y = data['age']\n",
    "\n",
    "# Add a constant term to the features\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform forward selection\n",
    "selected_features = []\n",
    "p_values = []\n",
    "num_features = X.shape[1] - 1  # Exclude the constant term\n",
    "\n",
    "for _ in range(num_features):\n",
    "    best_pvalue = np.inf\n",
    "    best_feature = None\n",
    "    \n",
    "    for feature in X.columns:\n",
    "        if feature not in selected_features:\n",
    "            model = sm.OLS(y, X[selected_features + [feature]]).fit()\n",
    "            pvalue = model.pvalues[feature]\n",
    "            \n",
    "            if pvalue < best_pvalue:\n",
    "                best_pvalue = pvalue\n",
    "                best_feature = feature\n",
    "    \n",
    "    if best_feature is not None:\n",
    "        selected_features.append(best_feature)\n",
    "        p_values.append(best_pvalue)\n",
    "\n",
    "# Print selected features and their p-values\n",
    "result = pd.DataFrame({\"Feature\": selected_features, \"P-value\": p_values})\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "we perform forward selection to select the best features.\n",
    "In each iteration, we iterate through the available features \n",
    "and fit a model with the selected features plus one additional feature.\n",
    "We compute the p-value for the additional feature \n",
    "and keep track of the feature with the lowest p-value.\n",
    "The feature with the lowest p-value is added to \n",
    "the selected features list. \n",
    "This process is repeated until all features have been evaluated.\n",
    "Finally, we print the selected features and\n",
    "their corresponding p-values in a DataFrame (result)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
